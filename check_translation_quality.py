#!/usr/bin/env python3
"""
ç¿»è¯‘è´¨é‡æ£€æŸ¥å·¥å…·
ç”¨äºæ£€æµ‹è¯­è¨€åŒ…ä¸­çš„è¯­è¨€æ··ä¹±ã€å¤§å†™é—®é¢˜ç­‰
"""

import json
import os
import re
from collections import defaultdict
import argparse


def load_json_file(filepath):
    """åŠ è½½JSONæ–‡ä»¶"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def check_english_in_non_english_file(data, language_code):
    """æ£€æŸ¥éè‹±æ–‡æ–‡ä»¶ä¸­çš„è‹±æ–‡å†…å®¹"""
    if language_code == 'en':
        return []
    
    issues = []
    english_pattern = re.compile(r'[A-Za-z]{3,}')
    
    # å¸¸è§çš„æœªç¿»è¯‘çš„è‹±æ–‡è¯æ±‡
    common_english_words = [
        'Please', 'Enter', 'Select', 'Password', 'Login',
        'Settings', 'Edit', 'Delete', 'Clear', 'Copy',
        'Download', 'Upload', 'Cancel', 'Confirm', 'Save',
        'verification', 'progress', 'merchant', 'payment',
        'Withdrawal', 'Payment'
    ]
    
    for key, value in data.items():
        if isinstance(value, str) and english_pattern.search(value):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§è‹±æ–‡è¯
            for word in common_english_words:
                if word.lower() in value.lower():
                    issues.append({
                        'key': key,
                        'value': value,
                        'issue': f'åŒ…å«è‹±æ–‡è¯æ±‡: {word}'
                    })
                    break
    
    return issues


def check_capitalization_issues(data, language_code):
    """æ£€æŸ¥å¤§å†™é—®é¢˜"""
    issues = []
    
    # ç½—æ›¼è¯­ç³»è¯­è¨€åº”è¯¥ä½¿ç”¨å°å†™
    lowercase_languages = ['es', 'fr', 'it', 'pt']
    
    if language_code in lowercase_languages:
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å½“çš„å¤§å†™
        for key, value in data.items():
            if isinstance(value, str) and len(value) > 0:
                # è·³è¿‡ç¼©å†™è¯å’Œå“ç‰Œå
                if value.isupper() or len(value) <= 3:
                    continue
                
                # æ£€æŸ¥é¦–å­—æ¯å¤§å†™çš„å•è¯ï¼ˆä¸åœ¨å¥é¦–ï¼‰
                words = value.split()
                if len(words) == 1 and words[0][0].isupper() and words[0][1:].islower():
                    # å•ä¸ªè¯ä¸”é¦–å­—æ¯å¤§å†™
                    issues.append({
                        'key': key,
                        'value': value,
                        'issue': f'{language_code}è¯­è¨€UIå…ƒç´ åº”è¯¥ä½¿ç”¨å°å†™'
                    })
    
    return issues


def check_translation_consistency(data, reference_keys):
    """æ£€æŸ¥ç¿»è¯‘å®Œæ•´æ€§"""
    missing_keys = []
    
    for key in reference_keys:
        if key not in data:
            missing_keys.append(key)
    
    return missing_keys


def analyze_language_file(filepath, reference_data=None):
    """åˆ†æå•ä¸ªè¯­è¨€æ–‡ä»¶"""
    filename = os.path.basename(filepath)
    language_code = filename.replace('.json', '')
    
    print(f"\n{'='*60}")
    print(f"åˆ†ææ–‡ä»¶: {filename}")
    print(f"{'='*60}")
    
    try:
        data = load_json_file(filepath)
        
        # 1. æ£€æŸ¥è‹±æ–‡æ··å…¥
        english_issues = check_english_in_non_english_file(data, language_code)
        if english_issues:
            print(f"\nâŒ å‘ç° {len(english_issues)} ä¸ªè‹±æ–‡æ··å…¥é—®é¢˜:")
            for issue in english_issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {issue['key']}: \"{issue['value']}\" ({issue['issue']})")
            if len(english_issues) > 10:
                print(f"  ... è¿˜æœ‰ {len(english_issues) - 10} ä¸ªé—®é¢˜")
        
        # 2. æ£€æŸ¥å¤§å†™é—®é¢˜
        cap_issues = check_capitalization_issues(data, language_code)
        if cap_issues:
            print(f"\nâš ï¸  å‘ç° {len(cap_issues)} ä¸ªå¤§å†™é—®é¢˜:")
            for issue in cap_issues[:5]:
                print(f"  - {issue['key']}: \"{issue['value']}\" ({issue['issue']})")
            if len(cap_issues) > 5:
                print(f"  ... è¿˜æœ‰ {len(cap_issues) - 5} ä¸ªé—®é¢˜")
        
        # 3. æ£€æŸ¥ç¼ºå¤±çš„é”®
        if reference_data:
            missing_keys = check_translation_consistency(data, reference_data.keys())
            if missing_keys:
                print(f"\nâš ï¸  ç¼ºå¤± {len(missing_keys)} ä¸ªç¿»è¯‘é”®:")
                for key in missing_keys[:5]:
                    print(f"  - {key}")
                if len(missing_keys) > 5:
                    print(f"  ... è¿˜æœ‰ {len(missing_keys) - 5} ä¸ªç¼ºå¤±")
        
        # 4. ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - æ€»æ¡ç›®æ•°: {len(data)}")
        print(f"  - è‹±æ–‡æ··å…¥ç‡: {len(english_issues)/len(data)*100:.1f}%")
        
        if not english_issues and not cap_issues:
            print(f"\nâœ… æ–‡ä»¶è´¨é‡è‰¯å¥½!")
        
        return {
            'language': language_code,
            'total_entries': len(data),
            'english_issues': len(english_issues),
            'cap_issues': len(cap_issues),
            'missing_keys': len(missing_keys) if reference_data else 0
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None


def check_directory(directory_path):
    """æ£€æŸ¥ç›®å½•ä¸­çš„æ‰€æœ‰è¯­è¨€æ–‡ä»¶"""
    print(f"æ£€æŸ¥ç›®å½•: {directory_path}")
    
    # é¦–å…ˆåŠ è½½å‚è€ƒæ–‡ä»¶ï¼ˆä¸­æ–‡ï¼‰
    reference_file = os.path.join(directory_path, 'zh-CN.json')
    reference_data = None
    
    if os.path.exists(reference_file):
        reference_data = load_json_file(reference_file)
        print(f"ä½¿ç”¨ zh-CN.json ä½œä¸ºå‚è€ƒ ({len(reference_data)} ä¸ªé”®)")
    
    # åˆ†ææ‰€æœ‰JSONæ–‡ä»¶
    results = []
    for filename in sorted(os.listdir(directory_path)):
        if filename.endswith('.json') and filename != 'zh-CN.json':
            filepath = os.path.join(directory_path, filename)
            result = analyze_language_file(filepath, reference_data)
            if result:
                results.append(result)
    
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("æ±‡æ€»æŠ¥å‘Š")
    print(f"{'='*60}")
    
    total_issues = sum(r['english_issues'] + r['cap_issues'] for r in results)
    
    if total_issues == 0:
        print("âœ… æ‰€æœ‰æ–‡ä»¶è´¨é‡è‰¯å¥½!")
    else:
        print(f"âš ï¸  å‘ç°æ€»è®¡ {total_issues} ä¸ªé—®é¢˜éœ€è¦ä¿®å¤")
        print("\nä¼˜å…ˆä¿®å¤å»ºè®®:")
        
        # æŒ‰é—®é¢˜æ•°é‡æ’åº
        sorted_results = sorted(results, 
                              key=lambda x: x['english_issues'] + x['cap_issues'], 
                              reverse=True)
        
        for i, result in enumerate(sorted_results[:5]):
            total = result['english_issues'] + result['cap_issues']
            if total > 0:
                print(f"{i+1}. {result['language']}.json - {total} ä¸ªé—®é¢˜ "
                      f"(è‹±æ–‡æ··å…¥: {result['english_issues']}, "
                      f"å¤§å†™é—®é¢˜: {result['cap_issues']})")


def main():
    parser = argparse.ArgumentParser(description='æ£€æŸ¥ç¿»è¯‘æ–‡ä»¶è´¨é‡')
    parser.add_argument('path', help='è¦æ£€æŸ¥çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--fix', action='store_true', help='å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜ï¼ˆæœªå®ç°ï¼‰')
    
    args = parser.parse_args()
    
    if os.path.isdir(args.path):
        check_directory(args.path)
    elif os.path.isfile(args.path):
        analyze_language_file(args.path)
    else:
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {args.path}")


if __name__ == "__main__":
    main()